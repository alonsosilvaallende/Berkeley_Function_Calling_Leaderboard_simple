{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ba3cc3-ee29-4115-a43a-2ccad3a69733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:28.700748Z",
     "iopub.status.busy": "2024-07-08T09:25:28.699927Z",
     "iopub.status.idle": "2024-07-08T09:25:28.705299Z",
     "shell.execute_reply": "2024-07-08T09:25:28.704228Z",
     "shell.execute_reply.started": "2024-07-08T09:25:28.700695Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN IT ONCE TO DOWNLOAD THE TEST DATASET\n",
    "# !wget https://raw.githubusercontent.com/ShishirPatil/gorilla/main/berkeley-function-call-leaderboard/data/possible_answer/gorilla_openfunctions_v1_test_simple.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8043c9-1889-429e-b945-7fa437010d28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:28.707567Z",
     "iopub.status.busy": "2024-07-08T09:25:28.706776Z",
     "iopub.status.idle": "2024-07-08T09:25:28.731192Z",
     "shell.execute_reply": "2024-07-08T09:25:28.729875Z",
     "shell.execute_reply.started": "2024-07-08T09:25:28.707506Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"gorilla_openfunctions_v1_test_simple.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1c1800-eefe-41be-b0f7-7bf86b36b728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:28.733649Z",
     "iopub.status.busy": "2024-07-08T09:25:28.732672Z",
     "iopub.status.idle": "2024-07-08T09:25:28.757595Z",
     "shell.execute_reply": "2024-07-08T09:25:28.756444Z",
     "shell.execute_reply.started": "2024-07-08T09:25:28.733602Z"
    }
   },
   "outputs": [],
   "source": [
    "# standardize possible_answers from gorilla simple test set\n",
    "import json\n",
    "\n",
    "possible_answers = []\n",
    "# Open the file and read line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        json_data = json.loads(line)\n",
    "        \n",
    "        # Process the JSON object\n",
    "        for function_name, params in json_data.items():\n",
    "            final_string = function_name + ',{'\n",
    "            for param_name, param_value in params.items():\n",
    "                final_string += '\"' + param_name + '\":' + str(param_value) +','\n",
    "            final_string = final_string[:-1] +\"}\"\n",
    "            final_string = final_string.replace(\"'\", '\"')\n",
    "            final_string = final_string.replace(\" \", \"\")\n",
    "            possible_answers.append(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8234108-d3bd-4bde-ac53-9ec59056102a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:28.759418Z",
     "iopub.status.busy": "2024-07-08T09:25:28.759022Z",
     "iopub.status.idle": "2024-07-08T09:25:28.787730Z",
     "shell.execute_reply": "2024-07-08T09:25:28.786619Z",
     "shell.execute_reply.started": "2024-07-08T09:25:28.759381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calculate_triangle_area,{\"base\":[10],\"height\":[5],\"unit\":[\"units\",\"\"]}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c6b9f1-d270-45a5-8fbe-65dd01913a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:28.789834Z",
     "iopub.status.busy": "2024-07-08T09:25:28.789228Z",
     "iopub.status.idle": "2024-07-08T09:25:31.794533Z",
     "shell.execute_reply": "2024-07-08T09:25:31.793322Z",
     "shell.execute_reply.started": "2024-07-08T09:25:28.789789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find the area of a triangle with a base of 10 ...</td>\n",
       "      <td>{'name': 'calculate_triangle_area', 'descripti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calculate the factorial of 5 using math functi...</td>\n",
       "      <td>{'name': 'math.factorial', 'description': 'Cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calculate the hypotenuse of a right triangle g...</td>\n",
       "      <td>{'name': 'math.hypot', 'description': 'Calcula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find the roots of a quadratic equation with co...</td>\n",
       "      <td>{'name': 'algebra.quadratic_roots', 'descripti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Solve a quadratic equation where a=2, b=6, and...</td>\n",
       "      <td>{'name': 'solve_quadratic_equation', 'descript...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Find the area of a triangle with a base of 10 ...   \n",
       "1  Calculate the factorial of 5 using math functi...   \n",
       "2  Calculate the hypotenuse of a right triangle g...   \n",
       "3  Find the roots of a quadratic equation with co...   \n",
       "4  Solve a quadratic equation where a=2, b=6, and...   \n",
       "\n",
       "                                            function  \n",
       "0  {'name': 'calculate_triangle_area', 'descripti...  \n",
       "1  {'name': 'math.factorial', 'description': 'Cal...  \n",
       "2  {'name': 'math.hypot', 'description': 'Calcula...  \n",
       "3  {'name': 'algebra.quadratic_roots', 'descripti...  \n",
       "4  {'name': 'solve_quadratic_equation', 'descript...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download questions and functions from gorilla dataset\n",
    "import pandas as pd\n",
    "df = pd.read_json(\"https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard/raw/main/gorilla_openfunctions_v1_test_simple.json\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aff844c-4e74-4513-b2cf-fe8b8f3ac263",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:31.799550Z",
     "iopub.status.busy": "2024-07-08T09:25:31.798848Z",
     "iopub.status.idle": "2024-07-08T09:25:35.186027Z",
     "shell.execute_reply": "2024-07-08T09:25:35.185592Z",
     "shell.execute_reply.started": "2024-07-08T09:25:31.799474Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /home/asilva/models/Hermes-2-Pro-Llama-3-8B-F16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Hermes-2-Pro-Llama-3-8B\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128288\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128288]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128288]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128003\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 128001\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {{bos_token}}{% for message in messag...\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:  226 tensors\n",
      "llm_load_vocab: special tokens cache size = 288\n",
      "llm_load_vocab: token to piece cache size = 0.8007 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128288\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = F16\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 14.96 GiB (16.00 BPW) \n",
      "llm_load_print_meta: general.name     = Hermes-2-Pro-Llama-3-8B\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128003 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128003 '<|im_end|>'\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_cuda_init: found 4 CUDA devices:\n",
      "  Device 0: NVIDIA RTX A4000, compute capability 8.6, VMM: yes\n",
      "  Device 1: NVIDIA RTX A4000, compute capability 8.6, VMM: yes\n",
      "  Device 2: NVIDIA RTX A4000, compute capability 8.6, VMM: yes\n",
      "  Device 3: NVIDIA RTX A4000, compute capability 8.6, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.74 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  1002.25 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3328.25 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =  3744.28 MiB\n",
      "llm_load_tensors:      CUDA2 buffer size =  3328.25 MiB\n",
      "llm_load_tensors:      CUDA3 buffer size =  3914.48 MiB\n",
      "..........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    16.00 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =    18.00 MiB\n",
      "llama_kv_cache_init:      CUDA2 KV buffer size =    16.00 MiB\n",
      "llama_kv_cache_init:      CUDA3 KV buffer size =    14.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model: pipeline parallelism enabled (n_copies=4)\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   108.01 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   108.01 MiB\n",
      "llama_new_context_with_model:      CUDA2 compute buffer size =   108.01 MiB\n",
      "llama_new_context_with_model:      CUDA3 compute buffer size =   294.58 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    12.02 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 5\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.ggml.eos_token_id': '128003', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Hermes-2-Pro-Llama-3-8B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '1', 'llama.vocab_size': '128288', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\"/home/asilva/models/Hermes-2-Pro-Llama-3-8B-F16.gguf\", n_gpu_layers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc6cf82-ed32-45d3-8449-cb86bace949c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:35.186859Z",
     "iopub.status.busy": "2024-07-08T09:25:35.186624Z",
     "iopub.status.idle": "2024-07-08T09:25:35.196426Z",
     "shell.execute_reply": "2024-07-08T09:25:35.196033Z",
     "shell.execute_reply.started": "2024-07-08T09:25:35.186842Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract from the response only the first of nested brackets\n",
    "import regex\n",
    "\n",
    "def extract_first_of_nested_brackets(input_string):\n",
    "    # Pattern to match the first complete set of brackets including nested ones\n",
    "    pattern = r'\\{(?:[^\\{\\}]*|(?R))*\\}'\n",
    "    match = regex.search(pattern, input_string)\n",
    "    if match:\n",
    "        return match.group(0)  # Returns the matched text including brackets\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fddb3-21bc-471d-899e-0d4c3eef7518",
   "metadata": {},
   "source": [
    "## Construction of the prompt for Hermes 2 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06af86c-a6ac-49de-873a-3b6a1fe5eb5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:35.197097Z",
     "iopub.status.busy": "2024-07-08T09:25:35.196946Z",
     "iopub.status.idle": "2024-07-08T09:25:35.216049Z",
     "shell.execute_reply": "2024-07-08T09:25:35.214786Z",
     "shell.execute_reply.started": "2024-07-08T09:25:35.197083Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de1cc2c-153f-44c8-b574-0d988383edc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:35.218066Z",
     "iopub.status.busy": "2024-07-08T09:25:35.217607Z",
     "iopub.status.idle": "2024-07-08T09:25:35.236032Z",
     "shell.execute_reply": "2024-07-08T09:25:35.234798Z",
     "shell.execute_reply.started": "2024-07-08T09:25:35.218021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find the area of a triangle with a base of 10 units and height of 5 units.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = df.iloc[pos][\"question\"]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e6e18a-a18c-48bd-8f20-f4db47ed35d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:35.238037Z",
     "iopub.status.busy": "2024-07-08T09:25:35.237581Z",
     "iopub.status.idle": "2024-07-08T09:25:35.254245Z",
     "shell.execute_reply": "2024-07-08T09:25:35.253037Z",
     "shell.execute_reply.started": "2024-07-08T09:25:35.237992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"calculate_triangle_area\", \"description\": \"Calculate the area of a triangle given its base and height.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"base\": {\"type\": \"integer\", \"description\": \"The base of the triangle.\"}, \"height\": {\"type\": \"integer\", \"description\": \"The height of the triangle.\"}, \"unit\": {\"type\": \"string\", \"description\": \"The unit of measure (defaults to \\'units\\' if not specified)\"}}, \"required\": [\"base\", \"height\"]}}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function = df.iloc[pos]['function']\n",
    "json.dumps(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e54312-723e-4f03-a220-2c9bbcdd9a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:35.256369Z",
     "iopub.status.busy": "2024-07-08T09:25:35.255813Z",
     "iopub.status.idle": "2024-07-08T09:25:35.272292Z",
     "shell.execute_reply": "2024-07-08T09:25:35.271039Z",
     "shell.execute_reply.started": "2024-07-08T09:25:35.256323Z"
    }
   },
   "outputs": [],
   "source": [
    "import json_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81ba8fc2-c287-4adf-a8cd-9615bc8bb9ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:35.274348Z",
     "iopub.status.busy": "2024-07-08T09:25:35.273866Z",
     "iopub.status.idle": "2024-07-08T09:25:35.291002Z",
     "shell.execute_reply": "2024-07-08T09:25:35.289804Z",
     "shell.execute_reply.started": "2024-07-08T09:25:35.274302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into functions. Here are the available tools: <tools> [{\"name\": \"calculate_triangle_area\", \"description\": \"Calculate the area of a triangle given its base and height.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"base\": {\"type\": \"integer\", \"description\": \"The base of the triangle.\"}, \"height\": {\"type\": \"integer\", \"description\": \"The height of the triangle.\"}, \"unit\": {\"type\": \"string\", \"description\": \"The unit of measure (defaults to \\'units\\' if not specified)\"}}, \"required\": [\"base\", \"height\"]}}] </tools> Use the following pydantic model json schema for each tool call you will make: {\\'title\\': \\'FunctionCall\\', \\'type\\': \\'object\\', \\'properties\\': {\\'arguments\\': {\\'title\\': \\'Arguments\\', \\'type\\': \\'object\\'}, \\'name\\': {\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}}, \\'required\\': [\\'arguments\\', \\'name\\']} For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows: <tool_call>\\n{\\'arguments\\': <args-dict>, \\'name\\': <function-name>}</tool_call><|im_end|>\\n<|im_start|>user\\nFind the area of a triangle with a base of 10 units and height of 5 units.<|im_start|>assistant\\n<tool_call>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = (\n",
    "    \"<|im_start|>system\\n\"\n",
    "    \"You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. \"\n",
    "    \"You may call one or more functions to assist with the user query. \"\n",
    "    \"Don't make assumptions about what values to plug into functions. \"\n",
    "    \"Here are the available tools: <tools> [\" + json.dumps(function) +\n",
    "    \"] </tools> Use the following pydantic model json schema for each tool call you will make: \"\n",
    "    \"{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']} \"\n",
    "    \"For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows: \"\n",
    "    \"<tool_call>\\n\"\n",
    "    \"{'arguments': <args-dict>, 'name': <function-name>}\"\n",
    "    \"</tool_call><|im_end|>\\n\"\n",
    "    \"<|im_start|>user\\n\" + question +\n",
    "    \"<|im_start|>assistant\\n\"\n",
    "    \"<tool_call>\"\n",
    ")\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "056956e7-a409-43ce-b534-5ebe4a16e776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:35.293028Z",
     "iopub.status.busy": "2024-07-08T09:25:35.292564Z",
     "iopub.status.idle": "2024-07-08T09:25:36.607729Z",
     "shell.execute_reply": "2024-07-08T09:25:36.607264Z",
     "shell.execute_reply.started": "2024-07-08T09:25:35.292982Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      34.21 ms /    25 runs   (    1.37 ms per token,   730.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.26 ms /   320 tokens (    0.77 ms per token,  1299.46 tokens per second)\n",
      "llama_print_timings:        eval time =     995.10 ms /    24 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =    1291.82 ms /   344 tokens\n"
     ]
    }
   ],
   "source": [
    "response = llm(final_prompt, temperature=0, seed=42, max_tokens=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0038b550-865d-4f97-95f4-c15d762fe9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:36.608534Z",
     "iopub.status.busy": "2024-07-08T09:25:36.608349Z",
     "iopub.status.idle": "2024-07-08T09:25:36.612389Z",
     "shell.execute_reply": "2024-07-08T09:25:36.612005Z",
     "shell.execute_reply.started": "2024-07-08T09:25:36.608518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\"arguments\": {\"base\": 10, \"height\": 5}, \"name\": \"calculate_triangle_area\"}</tool_call>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f6331b-cd07-481d-96ac-5f38115935d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:36.613057Z",
     "iopub.status.busy": "2024-07-08T09:25:36.612911Z",
     "iopub.status.idle": "2024-07-08T09:25:36.639488Z",
     "shell.execute_reply": "2024-07-08T09:25:36.638787Z",
     "shell.execute_reply.started": "2024-07-08T09:25:36.613043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"arguments\": {\"base\": 10, \"height\": 5}, \"name\": \"calculate_triangle_area\"}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract from the response only the first of nested brackets\n",
    "result = extract_first_of_nested_brackets(response['choices'][0]['text'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c71d2fb2-623d-464c-8646-b8b6022ffaf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:36.640800Z",
     "iopub.status.busy": "2024-07-08T09:25:36.640430Z",
     "iopub.status.idle": "2024-07-08T09:25:36.658840Z",
     "shell.execute_reply": "2024-07-08T09:25:36.657647Z",
     "shell.execute_reply.started": "2024-07-08T09:25:36.640773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calculate_triangle_area,{\"base\":10,\"height\":5}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize model_output\n",
    "final_result = str(json_repair.loads(result)[\"name\"]) + \",\" + str(json_repair.loads(result)[\"arguments\"])\n",
    "final_result = final_result.replace(\"'\",'\"')\n",
    "final_result = final_result.replace(\" \", \"\")\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b418f-79c1-407a-8557-6863627fb03b",
   "metadata": {},
   "source": [
    "## Run the simulation for all the TEST_CATEGORY = simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cb2455b-11d6-4c72-9d1b-9db1d4f5cd74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:25:36.660891Z",
     "iopub.status.busy": "2024-07-08T09:25:36.660425Z",
     "iopub.status.idle": "2024-07-08T09:36:27.344056Z",
     "shell.execute_reply": "2024-07-08T09:36:27.343311Z",
     "shell.execute_reply.started": "2024-07-08T09:25:36.660846Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      34.01 ms /    25 runs   (    1.36 ms per token,   735.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1042.69 ms /    25 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1091.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      27.59 ms /    20 runs   (    1.38 ms per token,   724.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      90.99 ms /   195 tokens (    0.47 ms per token,  2143.00 tokens per second)\n",
      "llama_print_timings:        eval time =     790.93 ms /    19 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =     919.93 ms /   214 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.30 ms /    27 runs   (    1.38 ms per token,   723.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.67 ms /   281 tokens (    0.46 ms per token,  2167.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.83 ms /    26 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1266.36 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.12 ms /    34 runs   (    1.39 ms per token,   721.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.39 ms /   256 tokens (    0.42 ms per token,  2406.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.20 ms /    33 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1546.69 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.38 ms /    34 runs   (    1.33 ms per token,   749.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.12 ms /   245 tokens (    0.41 ms per token,  2422.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.72 ms /    33 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1538.81 ms /   278 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.07 ms /    32 runs   (    1.35 ms per token,   743.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     139.09 ms /   341 tokens (    0.41 ms per token,  2451.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1293.16 ms /    31 runs   (   41.71 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    1492.75 ms /   372 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.57 ms /    32 runs   (    1.36 ms per token,   734.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.29 ms /   241 tokens (    0.42 ms per token,  2403.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.36 ms /    31 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1452.11 ms /   272 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.93 ms /    30 runs   (    1.36 ms per token,   732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.81 ms /   234 tokens (    0.44 ms per token,  2298.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.87 ms /    29 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1365.44 ms /   263 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      27.50 ms /    20 runs   (    1.37 ms per token,   727.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.27 ms /   227 tokens (    0.44 ms per token,  2263.93 tokens per second)\n",
      "llama_print_timings:        eval time =     791.55 ms /    19 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =     930.31 ms /   246 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      28.05 ms /    20 runs   (    1.40 ms per token,   713.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.24 ms /   227 tokens (    0.44 ms per token,  2264.54 tokens per second)\n",
      "llama_print_timings:        eval time =     791.20 ms /    19 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =     929.54 ms /   246 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      34.48 ms /    25 runs   (    1.38 ms per token,   724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.47 ms /   274 tokens (    0.47 ms per token,  2132.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1000.23 ms /    24 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1176.30 ms /   298 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.10 ms /    26 runs   (    1.35 ms per token,   740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.03 ms /   233 tokens (    0.43 ms per token,  2352.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.37 ms /    25 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1188.39 ms /   258 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      28.89 ms /    21 runs   (    1.38 ms per token,   726.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.93 ms /   222 tokens (    0.45 ms per token,  2244.01 tokens per second)\n",
      "llama_print_timings:        eval time =     832.83 ms /    20 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =     972.27 ms /   242 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.61 ms /    31 runs   (    1.41 ms per token,   710.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.75 ms /   289 tokens (    0.45 ms per token,  2244.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.25 ms /    30 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1438.29 ms /   319 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.53 ms /    36 runs   (    1.29 ms per token,   773.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.15 ms /   230 tokens (    0.43 ms per token,  2343.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.58 ms /    35 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1620.65 ms /   265 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.02 ms /    42 runs   (    1.36 ms per token,   736.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.31 ms /   326 tokens (    0.42 ms per token,  2356.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1709.80 ms /    41 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1926.91 ms /   367 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.82 ms /    30 runs   (    1.36 ms per token,   734.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.88 ms /   268 tokens (    0.47 ms per token,  2112.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.23 ms /    29 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1391.74 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      33.35 ms /    24 runs   (    1.39 ms per token,   719.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.13 ms /   223 tokens (    0.44 ms per token,  2249.62 tokens per second)\n",
      "llama_print_timings:        eval time =     957.81 ms /    23 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1102.68 ms /   246 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      27.10 ms /    19 runs   (    1.43 ms per token,   701.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.49 ms /   195 tokens (    0.48 ms per token,  2085.78 tokens per second)\n",
      "llama_print_timings:        eval time =     749.53 ms /    18 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =     880.07 ms /   213 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.17 ms /    27 runs   (    1.38 ms per token,   726.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.25 ms /   219 tokens (    0.45 ms per token,  2229.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.59 ms /    26 runs   (   41.64 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1231.86 ms /   245 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.39 ms /    27 runs   (    1.35 ms per token,   741.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.49 ms /   214 tokens (    0.44 ms per token,  2264.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.27 ms /    26 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1226.29 ms /   240 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.16 ms /    29 runs   (    1.63 ms per token,   614.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.88 ms /   229 tokens (    0.43 ms per token,  2339.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.70 ms /    28 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time =    1328.82 ms /   257 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.76 ms /    28 runs   (    1.38 ms per token,   722.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.53 ms /   227 tokens (    0.43 ms per token,  2327.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.44 ms /    27 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1274.42 ms /   254 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.65 ms /    27 runs   (    1.39 ms per token,   717.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.16 ms /   263 tokens (    0.48 ms per token,  2084.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.34 ms /    26 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1261.43 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.79 ms /    29 runs   (    1.37 ms per token,   728.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.09 ms /   218 tokens (    0.45 ms per token,  2222.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.94 ms /    28 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1317.68 ms /   246 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.77 ms /    26 runs   (    1.41 ms per token,   707.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.31 ms /   293 tokens (    0.44 ms per token,  2265.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.59 ms /    25 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1219.56 ms /   318 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      33.91 ms /    25 runs   (    1.36 ms per token,   737.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.61 ms /   273 tokens (    0.47 ms per token,  2122.75 tokens per second)\n",
      "llama_print_timings:        eval time =     999.81 ms /    24 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1175.95 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.58 ms /    32 runs   (    1.36 ms per token,   734.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.93 ms /   291 tokens (    0.44 ms per token,  2257.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1292.13 ms /    31 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1480.56 ms /   322 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.50 ms /    35 runs   (    1.36 ms per token,   736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.69 ms /   284 tokens (    0.45 ms per token,  2224.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.54 ms /    34 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1609.30 ms /   318 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      29.94 ms /    21 runs   (    1.43 ms per token,   701.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.69 ms /   305 tokens (    0.43 ms per token,  2316.06 tokens per second)\n",
      "llama_print_timings:        eval time =     833.73 ms /    20 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1005.54 ms /   325 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.86 ms /    30 runs   (    1.43 ms per token,   699.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.88 ms /   286 tokens (    0.45 ms per token,  2219.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.54 ms /    29 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1395.78 ms /   315 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.47 ms /    35 runs   (    1.41 ms per token,   707.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.95 ms /   282 tokens (    0.45 ms per token,  2203.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.74 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1611.78 ms /   316 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.95 ms /    26 runs   (    1.42 ms per token,   703.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.95 ms /   261 tokens (    0.47 ms per token,  2122.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.65 ms /    25 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1214.48 ms /   286 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.79 ms /    37 runs   (    1.43 ms per token,   700.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.66 ms /   271 tokens (    0.46 ms per token,  2173.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.96 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1696.29 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      60.04 ms /    42 runs   (    1.43 ms per token,   699.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.12 ms /   309 tokens (    0.43 ms per token,  2321.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1709.27 ms /    41 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1923.74 ms /   350 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.22 ms /    35 runs   (    1.43 ms per token,   696.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.06 ms /   283 tokens (    0.45 ms per token,  2209.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1417.00 ms /    34 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1613.37 ms /   317 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.04 ms /    34 runs   (    1.38 ms per token,   722.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.25 ms /   269 tokens (    0.47 ms per token,  2147.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.03 ms /    33 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1564.39 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.58 ms /    43 runs   (    1.43 ms per token,   698.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.83 ms /   300 tokens (    0.44 ms per token,  2293.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.62 ms /    42 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1964.34 ms /   342 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.48 ms /    40 runs   (    1.34 ms per token,   747.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     134.55 ms /   312 tokens (    0.43 ms per token,  2318.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1625.83 ms /    39 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1833.86 ms /   351 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.10 ms /    26 runs   (    1.43 ms per token,   700.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.06 ms /   277 tokens (    0.46 ms per token,  2197.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.82 ms /    25 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1218.04 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.01 ms /    26 runs   (    1.42 ms per token,   702.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.48 ms /   282 tokens (    0.45 ms per token,  2212.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.67 ms /    25 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1219.41 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.02 ms /    34 runs   (    1.38 ms per token,   723.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.47 ms /   320 tokens (    0.42 ms per token,  2362.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.99 ms /    33 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1575.49 ms /   353 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.82 ms /    37 runs   (    1.43 ms per token,   700.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.30 ms /   296 tokens (    0.44 ms per token,  2254.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.12 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1703.18 ms /   332 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.00 ms /    28 runs   (    1.39 ms per token,   717.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.82 ms /   296 tokens (    0.44 ms per token,  2279.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.31 ms /    27 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1307.55 ms /   323 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.94 ms /    29 runs   (    1.41 ms per token,   708.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.50 ms /   268 tokens (    0.46 ms per token,  2152.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.30 ms /    28 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1345.93 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.43 ms /    36 runs   (    1.46 ms per token,   686.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.48 ms /   299 tokens (    0.44 ms per token,  2291.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.59 ms /    35 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1659.16 ms /   334 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.33 ms /    41 runs   (    1.33 ms per token,   754.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     145.61 ms /   365 tokens (    0.40 ms per token,  2506.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1668.65 ms /    40 runs   (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    1890.94 ms /   405 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.12 ms /    33 runs   (    1.40 ms per token,   715.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.56 ms /   242 tokens (    0.42 ms per token,  2406.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.82 ms /    32 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1496.25 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      34.09 ms /    25 runs   (    1.36 ms per token,   733.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.25 ms /   264 tokens (    0.47 ms per token,  2142.02 tokens per second)\n",
      "llama_print_timings:        eval time =     999.91 ms /    24 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1169.56 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.54 ms /    30 runs   (    1.38 ms per token,   722.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.18 ms /   255 tokens (    0.40 ms per token,  2471.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.91 ms /    29 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1367.35 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      65.88 ms /    48 runs   (    1.37 ms per token,   728.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.43 ms /   349 tokens (    0.41 ms per token,  2467.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1960.24 ms /    47 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2192.18 ms /   396 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.52 ms /    34 runs   (    1.37 ms per token,   730.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.43 ms /   299 tokens (    0.44 ms per token,  2292.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.27 ms /    33 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1569.47 ms /   332 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.41 ms /    26 runs   (    1.40 ms per token,   714.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.89 ms /   268 tokens (    0.47 ms per token,  2145.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.27 ms /    25 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1215.13 ms /   293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      31.58 ms /    23 runs   (    1.37 ms per token,   728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.41 ms /   271 tokens (    0.46 ms per token,  2160.84 tokens per second)\n",
      "llama_print_timings:        eval time =     916.85 ms /    22 runs   (   41.68 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1085.00 ms /   293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.31 ms /    32 runs   (    1.38 ms per token,   722.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.63 ms /   233 tokens (    0.42 ms per token,  2362.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1290.91 ms /    31 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1450.13 ms /   264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.40 ms /    29 runs   (    1.39 ms per token,   717.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.90 ms /   234 tokens (    0.42 ms per token,  2366.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.17 ms /    28 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1319.80 ms /   262 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.14 ms /    34 runs   (    1.39 ms per token,   721.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.19 ms /   235 tokens (    0.42 ms per token,  2369.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.32 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1537.33 ms /   268 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.60 ms /    31 runs   (    1.41 ms per token,   711.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.70 ms /   304 tokens (    0.43 ms per token,  2308.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.54 ms /    30 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1441.97 ms /   334 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.83 ms /    42 runs   (    1.40 ms per token,   713.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.92 ms /   275 tokens (    0.46 ms per token,  2183.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.60 ms /    41 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1914.61 ms /   316 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.08 ms /    34 runs   (    1.38 ms per token,   722.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.06 ms /   235 tokens (    0.42 ms per token,  2372.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.42 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1537.38 ms /   268 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.23 ms /    24 runs   (    1.47 ms per token,   681.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.10 ms /   268 tokens (    0.47 ms per token,  2142.35 tokens per second)\n",
      "llama_print_timings:        eval time =     958.48 ms /    23 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1131.05 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.27 ms /    33 runs   (    1.43 ms per token,   698.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.92 ms /   295 tokens (    0.44 ms per token,  2270.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.47 ms /    32 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1526.87 ms /   327 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.78 ms /    48 runs   (    1.29 ms per token,   776.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.68 ms /   305 tokens (    0.43 ms per token,  2316.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1959.24 ms /    47 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2176.84 ms /   352 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      69.36 ms /    51 runs   (    1.36 ms per token,   735.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.48 ms /   258 tokens (    0.47 ms per token,  2106.38 tokens per second)\n",
      "llama_print_timings:        eval time =    2083.06 ms /    50 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    2301.13 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.15 ms /    31 runs   (    1.39 ms per token,   718.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.66 ms /   264 tokens (    0.47 ms per token,  2134.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.85 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1432.47 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.64 ms /    42 runs   (    1.37 ms per token,   728.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.46 ms /   299 tokens (    0.44 ms per token,  2291.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.88 ms /    41 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1918.63 ms /   340 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.86 ms /    34 runs   (    1.44 ms per token,   695.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     121.56 ms /   257 tokens (    0.47 ms per token,  2114.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.78 ms /    33 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1561.77 ms /   290 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.42 ms /    33 runs   (    1.38 ms per token,   726.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.97 ms /   254 tokens (    0.41 ms per token,  2466.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.05 ms /    32 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1498.09 ms /   286 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.68 ms /    37 runs   (    1.42 ms per token,   702.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.69 ms /   276 tokens (    0.46 ms per token,  2178.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.08 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1698.17 ms /   312 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.88 ms /    37 runs   (    1.38 ms per token,   727.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.13 ms /   255 tokens (    0.40 ms per token,  2472.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.44 ms /    36 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1671.61 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.42 ms /    31 runs   (    1.43 ms per token,   697.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.62 ms /   306 tokens (    0.44 ms per token,  2290.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.24 ms /    30 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1443.88 ms /   336 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.90 ms /    37 runs   (    1.40 ms per token,   712.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.17 ms /   271 tokens (    0.46 ms per token,  2165.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.80 ms /    36 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1695.46 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.79 ms /    42 runs   (    1.28 ms per token,   780.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.53 ms /   323 tokens (    0.42 ms per token,  2365.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1709.61 ms /    41 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1921.18 ms /   364 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.50 ms /    28 runs   (    1.38 ms per token,   727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.17 ms /   263 tokens (    0.47 ms per token,  2135.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.17 ms /    27 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1301.00 ms /   290 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.62 ms /    39 runs   (    1.40 ms per token,   714.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.64 ms /   303 tokens (    0.45 ms per token,  2233.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.89 ms /    38 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1794.78 ms /   341 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.92 ms /    37 runs   (    1.38 ms per token,   726.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.82 ms /   270 tokens (    0.46 ms per token,  2163.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.02 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1694.07 ms /   306 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.58 ms /    36 runs   (    1.40 ms per token,   711.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.17 ms /   276 tokens (    0.47 ms per token,  2120.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.44 ms /    35 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1657.80 ms /   311 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.05 ms /    33 runs   (    1.46 ms per token,   686.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.61 ms /   264 tokens (    0.48 ms per token,  2085.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.63 ms /    32 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1525.82 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.09 ms /    32 runs   (    1.41 ms per token,   709.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.83 ms /   277 tokens (    0.47 ms per token,  2133.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.93 ms /    31 runs   (   41.68 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1483.49 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.02 ms /    43 runs   (    1.30 ms per token,   767.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.47 ms /   264 tokens (    0.48 ms per token,  2087.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.16 ms /    42 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1955.08 ms /   306 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.38 ms /    43 runs   (    1.43 ms per token,   700.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     132.21 ms /   307 tokens (    0.43 ms per token,  2322.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.87 ms /    42 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1965.84 ms /   349 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.92 ms /    38 runs   (    1.42 ms per token,   704.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.40 ms /   266 tokens (    0.47 ms per token,  2138.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.57 ms /    37 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1738.48 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.35 ms /    37 runs   (    1.33 ms per token,   749.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.32 ms /   223 tokens (    0.43 ms per token,  2315.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.06 ms /    36 runs   (   41.64 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1663.38 ms /   259 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      67.43 ms /    51 runs   (    1.32 ms per token,   756.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.59 ms /   304 tokens (    0.43 ms per token,  2310.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2084.47 ms /    50 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2309.86 ms /   354 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.24 ms /    26 runs   (    1.39 ms per token,   717.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.46 ms /   270 tokens (    0.46 ms per token,  2169.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.54 ms /    25 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1215.05 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.47 ms /    40 runs   (    1.39 ms per token,   721.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.54 ms /   293 tokens (    0.44 ms per token,  2261.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1625.85 ms /    39 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1830.55 ms /   332 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.83 ms /    45 runs   (    1.37 ms per token,   727.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     137.84 ms /   312 tokens (    0.44 ms per token,  2263.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1834.55 ms /    44 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2057.83 ms /   356 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.34 ms /    37 runs   (    1.31 ms per token,   765.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     104.31 ms /   246 tokens (    0.42 ms per token,  2358.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.71 ms /    36 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1671.84 ms /   282 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.07 ms /    30 runs   (    1.44 ms per token,   696.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     104.29 ms /   247 tokens (    0.42 ms per token,  2368.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.78 ms /    29 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1369.63 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      68.57 ms /    48 runs   (    1.43 ms per token,   699.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     145.31 ms /   349 tokens (    0.42 ms per token,  2401.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1961.60 ms /    47 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time =    2201.54 ms /   396 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.75 ms /    41 runs   (    1.43 ms per token,   697.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.65 ms /   299 tokens (    0.45 ms per token,  2237.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.41 ms /    40 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1881.28 ms /   339 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.23 ms /    37 runs   (    1.41 ms per token,   708.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.65 ms /   261 tokens (    0.47 ms per token,  2110.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.93 ms /    36 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1695.04 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.47 ms /    35 runs   (    1.41 ms per token,   707.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.70 ms /   273 tokens (    0.48 ms per token,  2104.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.69 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1614.03 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.29 ms /    36 runs   (    1.45 ms per token,   688.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.45 ms /   294 tokens (    0.45 ms per token,  2203.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.20 ms /    35 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1663.48 ms /   329 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.52 ms /    45 runs   (    1.37 ms per token,   731.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     137.56 ms /   312 tokens (    0.44 ms per token,  2268.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1833.92 ms /    44 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2055.58 ms /   356 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.91 ms /    27 runs   (    1.40 ms per token,   712.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     104.71 ms /   248 tokens (    0.42 ms per token,  2368.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.73 ms /    26 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1240.23 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      79.15 ms /    57 runs   (    1.39 ms per token,   720.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.19 ms /   310 tokens (    0.44 ms per token,  2276.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2335.71 ms /    56 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2582.08 ms /   366 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      27.75 ms /    20 runs   (    1.39 ms per token,   720.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.47 ms /   189 tokens (    0.56 ms per token,  1775.23 tokens per second)\n",
      "llama_print_timings:        eval time =     789.90 ms /    19 runs   (   41.57 ms per token,    24.05 tokens per second)\n",
      "llama_print_timings:       total time =     936.31 ms /   208 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.55 ms /    25 runs   (    1.42 ms per token,   703.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.13 ms /   267 tokens (    0.46 ms per token,  2150.92 tokens per second)\n",
      "llama_print_timings:        eval time =     999.81 ms /    24 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1172.37 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.51 ms /    39 runs   (    1.37 ms per token,   728.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.67 ms /   324 tokens (    0.44 ms per token,  2287.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.44 ms /    38 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1799.79 ms /   362 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      34.22 ms /    24 runs   (    1.43 ms per token,   701.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.05 ms /   257 tokens (    0.48 ms per token,  2088.51 tokens per second)\n",
      "llama_print_timings:        eval time =     958.41 ms /    23 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1128.16 ms /   280 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.19 ms /    25 runs   (    1.41 ms per token,   710.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.63 ms /   269 tokens (    0.46 ms per token,  2158.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1000.06 ms /    24 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1172.18 ms /   293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.62 ms /    34 runs   (    1.37 ms per token,   729.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.44 ms /   242 tokens (    0.42 ms per token,  2409.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.67 ms /    33 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1538.81 ms /   275 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.03 ms /    39 runs   (    1.33 ms per token,   749.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.63 ms /   318 tokens (    0.43 ms per token,  2344.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.60 ms /    38 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1792.31 ms /   356 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.34 ms /    26 runs   (    1.36 ms per token,   735.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     105.16 ms /   250 tokens (    0.42 ms per token,  2377.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.44 ms /    25 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1195.19 ms /   275 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.45 ms /    27 runs   (    1.35 ms per token,   740.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.75 ms /   248 tokens (    0.41 ms per token,  2437.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.01 ms /    26 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1234.44 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.92 ms /    38 runs   (    1.42 ms per token,   704.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.79 ms /   271 tokens (    0.47 ms per token,  2120.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.16 ms /    37 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1744.17 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.74 ms /    26 runs   (    1.37 ms per token,   727.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.11 ms /   278 tokens (    0.45 ms per token,  2204.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.78 ms /    25 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1216.15 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.60 ms /    41 runs   (    1.36 ms per token,   737.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.85 ms /   283 tokens (    0.45 ms per token,  2213.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.95 ms /    40 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1872.16 ms /   323 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.15 ms /    35 runs   (    1.40 ms per token,   712.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.53 ms /   259 tokens (    0.47 ms per token,  2113.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.53 ms /    34 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1605.49 ms /   293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.47 ms /    43 runs   (    1.36 ms per token,   735.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.52 ms /   307 tokens (    0.44 ms per token,  2265.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1751.18 ms /    42 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1967.85 ms /   349 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.80 ms /    27 runs   (    1.36 ms per token,   733.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.34 ms /   232 tokens (    0.44 ms per token,  2289.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.71 ms /    26 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1235.11 ms /   258 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.66 ms /    31 runs   (    1.38 ms per token,   726.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.64 ms /   258 tokens (    0.49 ms per token,  2053.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.13 ms /    30 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1434.22 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.18 ms /    30 runs   (    1.44 ms per token,   694.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.47 ms /   285 tokens (    0.46 ms per token,  2184.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.63 ms /    29 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1398.68 ms /   314 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.06 ms /    29 runs   (    1.38 ms per token,   723.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.03 ms /   262 tokens (    0.48 ms per token,  2078.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.54 ms /    28 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1347.42 ms /   290 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.56 ms /    41 runs   (    1.38 ms per token,   724.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.28 ms /   284 tokens (    0.46 ms per token,  2179.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.23 ms /    40 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1875.15 ms /   324 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.95 ms /    31 runs   (    1.39 ms per token,   721.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.33 ms /   264 tokens (    0.48 ms per token,  2089.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.02 ms /    30 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1435.79 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.25 ms /    37 runs   (    1.44 ms per token,   694.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.03 ms /   273 tokens (    0.47 ms per token,  2132.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.75 ms /    36 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1699.17 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      79.54 ms /    62 runs   (    1.28 ms per token,   779.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     137.84 ms /   309 tokens (    0.45 ms per token,  2241.66 tokens per second)\n",
      "llama_print_timings:        eval time =    2542.83 ms /    61 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2793.25 ms /   370 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      85.20 ms /    66 runs   (    1.29 ms per token,   774.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.65 ms /   320 tokens (    0.43 ms per token,  2341.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2710.20 ms /    65 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2965.71 ms /   385 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      77.84 ms /    61 runs   (    1.28 ms per token,   783.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.21 ms /   312 tokens (    0.43 ms per token,  2342.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2501.28 ms /    60 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2743.80 ms /   372 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.72 ms /    39 runs   (    1.33 ms per token,   754.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.03 ms /   273 tokens (    0.47 ms per token,  2132.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.32 ms /    38 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1782.58 ms /   311 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.67 ms /    37 runs   (    1.34 ms per token,   744.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.91 ms /   267 tokens (    0.46 ms per token,  2154.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.77 ms /    36 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1691.30 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      95.09 ms /    76 runs   (    1.25 ms per token,   799.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     147.33 ms /   356 tokens (    0.41 ms per token,  2416.39 tokens per second)\n",
      "llama_print_timings:        eval time =    3128.95 ms /    75 runs   (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    3412.72 ms /   431 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.50 ms /    39 runs   (    1.29 ms per token,   772.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     134.50 ms /   299 tokens (    0.45 ms per token,  2223.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.10 ms /    38 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1789.25 ms /   337 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.80 ms /    41 runs   (    1.36 ms per token,   734.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.70 ms /   295 tokens (    0.44 ms per token,  2274.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.08 ms /    40 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1873.57 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      73.26 ms /    50 runs   (    1.47 ms per token,   682.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.32 ms /   294 tokens (    0.44 ms per token,  2273.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2042.60 ms /    49 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2270.76 ms /   343 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      62.75 ms /    46 runs   (    1.36 ms per token,   733.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     132.86 ms /   310 tokens (    0.43 ms per token,  2333.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1875.92 ms /    45 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2095.16 ms /   355 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.82 ms /    41 runs   (    1.41 ms per token,   709.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.74 ms /   261 tokens (    0.48 ms per token,  2075.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.66 ms /    40 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1871.09 ms /   301 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.72 ms /    37 runs   (    1.42 ms per token,   701.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.90 ms /   306 tokens (    0.43 ms per token,  2319.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.66 ms /    36 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1703.98 ms /   342 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      73.49 ms /    55 runs   (    1.34 ms per token,   748.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.62 ms /   326 tokens (    0.43 ms per token,  2351.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2252.03 ms /    54 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2492.10 ms /   380 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.61 ms /    41 runs   (    1.36 ms per token,   737.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.27 ms /   331 tokens (    0.43 ms per token,  2343.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1668.38 ms /    40 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1887.12 ms /   371 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      60.02 ms /    46 runs   (    1.30 ms per token,   766.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.50 ms /   302 tokens (    0.45 ms per token,  2212.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1875.71 ms /    45 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2095.99 ms /   347 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      69.56 ms /    50 runs   (    1.39 ms per token,   718.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.76 ms /   325 tokens (    0.43 ms per token,  2342.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2043.29 ms /    49 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2276.88 ms /   374 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.15 ms /    38 runs   (    1.43 ms per token,   701.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.75 ms /   270 tokens (    0.48 ms per token,  2097.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.45 ms /    37 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1743.67 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.95 ms /    38 runs   (    1.37 ms per token,   731.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.58 ms /   281 tokens (    0.45 ms per token,  2219.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.11 ms /    37 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1738.68 ms /   318 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.77 ms /    42 runs   (    1.38 ms per token,   727.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     140.88 ms /   322 tokens (    0.44 ms per token,  2285.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1709.72 ms /    41 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1930.70 ms /   363 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.19 ms /    39 runs   (    1.42 ms per token,   706.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.94 ms /   326 tokens (    0.43 ms per token,  2346.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.92 ms /    38 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1799.00 ms /   364 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      64.25 ms /    45 runs   (    1.43 ms per token,   700.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     139.31 ms /   330 tokens (    0.42 ms per token,  2368.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1834.67 ms /    44 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2061.19 ms /   374 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.48 ms /    39 runs   (    1.42 ms per token,   702.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.71 ms /   300 tokens (    0.44 ms per token,  2295.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.09 ms /    38 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1789.86 ms /   338 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.81 ms /    38 runs   (    1.39 ms per token,   719.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.18 ms /   287 tokens (    0.46 ms per token,  2187.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.77 ms /    37 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1745.09 ms /   324 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.65 ms /    27 runs   (    1.39 ms per token,   717.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.41 ms /   227 tokens (    0.43 ms per token,  2330.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.81 ms /    26 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1230.62 ms /   253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.57 ms /    38 runs   (    1.38 ms per token,   722.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.06 ms /   273 tokens (    0.46 ms per token,  2182.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.26 ms /    37 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1737.37 ms /   310 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.17 ms /    33 runs   (    1.40 ms per token,   714.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.85 ms /   251 tokens (    0.41 ms per token,  2440.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.21 ms /    32 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1497.73 ms /   283 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.04 ms /    35 runs   (    1.37 ms per token,   728.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     139.46 ms /   328 tokens (    0.43 ms per token,  2351.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1417.50 ms /    34 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1621.92 ms /   362 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.98 ms /    37 runs   (    1.38 ms per token,   725.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     134.97 ms /   316 tokens (    0.43 ms per token,  2341.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.82 ms /    36 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1704.50 ms /   352 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.71 ms /    26 runs   (    1.37 ms per token,   728.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.49 ms /   270 tokens (    0.46 ms per token,  2168.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.44 ms /    25 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1213.55 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.74 ms /    30 runs   (    1.39 ms per token,   718.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.70 ms /   252 tokens (    0.41 ms per token,  2453.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.81 ms /    29 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1366.10 ms /   281 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.92 ms /    40 runs   (    1.37 ms per token,   728.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.20 ms /   312 tokens (    0.43 ms per token,  2307.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1625.64 ms /    39 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1834.98 ms /   351 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.15 ms /    25 runs   (    1.41 ms per token,   711.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.22 ms /   213 tokens (    0.44 ms per token,  2260.69 tokens per second)\n",
      "llama_print_timings:        eval time =     999.11 ms /    24 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1140.28 ms /   237 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.64 ms /    35 runs   (    1.53 ms per token,   652.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.40 ms /   277 tokens (    0.46 ms per token,  2174.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1418.14 ms /    34 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1617.48 ms /   311 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.61 ms /    31 runs   (    1.41 ms per token,   710.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.94 ms /   261 tokens (    0.47 ms per token,  2105.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.82 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1433.91 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.27 ms /    40 runs   (    1.41 ms per token,   710.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.52 ms /   286 tokens (    0.46 ms per token,  2191.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1625.39 ms /    39 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1832.29 ms /   325 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.68 ms /    41 runs   (    1.36 ms per token,   736.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.12 ms /   317 tokens (    0.43 ms per token,  2346.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.41 ms /    40 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1878.00 ms /   357 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.44 ms /    38 runs   (    1.38 ms per token,   724.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     137.84 ms /   331 tokens (    0.42 ms per token,  2401.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.75 ms /    37 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1751.24 ms /   368 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.12 ms /    39 runs   (    1.39 ms per token,   720.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     132.08 ms /   298 tokens (    0.44 ms per token,  2256.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.55 ms /    38 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1788.17 ms /   336 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.25 ms /    30 runs   (    1.44 ms per token,   693.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.91 ms /   262 tokens (    0.47 ms per token,  2131.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.92 ms /    29 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1388.14 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      59.31 ms /    43 runs   (    1.38 ms per token,   725.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.91 ms /   296 tokens (    0.44 ms per token,  2278.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.34 ms /    42 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1960.31 ms /   338 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      63.66 ms /    48 runs   (    1.33 ms per token,   753.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.12 ms /   297 tokens (    0.44 ms per token,  2282.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1958.87 ms /    47 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2176.47 ms /   344 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.72 ms /    34 runs   (    1.37 ms per token,   727.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.34 ms /   246 tokens (    0.41 ms per token,  2427.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.36 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1538.60 ms /   279 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.26 ms /    39 runs   (    1.34 ms per token,   746.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.81 ms /   274 tokens (    0.46 ms per token,  2160.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1582.73 ms /    38 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1780.30 ms /   312 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.91 ms /    36 runs   (    1.41 ms per token,   707.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.18 ms /   279 tokens (    0.45 ms per token,  2211.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.17 ms /    35 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1651.96 ms /   314 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.34 ms /    40 runs   (    1.41 ms per token,   709.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.94 ms /   266 tokens (    0.47 ms per token,  2146.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1624.42 ms /    39 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1824.16 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      60.93 ms /    44 runs   (    1.38 ms per token,   722.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.01 ms /   301 tokens (    0.44 ms per token,  2263.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1792.01 ms /    43 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    2007.58 ms /   344 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.80 ms /    41 runs   (    1.51 ms per token,   663.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.44 ms /   282 tokens (    0.46 ms per token,  2161.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1670.71 ms /    40 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
      "llama_print_timings:       total time =    1885.61 ms /   322 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.08 ms /    36 runs   (    1.36 ms per token,   733.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.09 ms /   254 tokens (    0.41 ms per token,  2463.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.78 ms /    35 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1628.17 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.25 ms /    37 runs   (    1.44 ms per token,   694.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.94 ms /   298 tokens (    0.44 ms per token,  2258.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.40 ms /    36 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1703.75 ms /   334 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.40 ms /    35 runs   (    1.38 ms per token,   723.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.18 ms /   245 tokens (    0.41 ms per token,  2421.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.11 ms /    34 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1583.58 ms /   279 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      60.98 ms /    45 runs   (    1.36 ms per token,   737.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     137.75 ms /   325 tokens (    0.42 ms per token,  2359.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1834.67 ms /    44 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2056.29 ms /   369 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.78 ms /    35 runs   (    1.42 ms per token,   703.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.65 ms /   285 tokens (    0.45 ms per token,  2232.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.98 ms /    34 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1612.40 ms /   319 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.78 ms /    40 runs   (    1.37 ms per token,   730.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.33 ms /   290 tokens (    0.45 ms per token,  2242.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1625.80 ms /    39 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1830.16 ms /   329 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.98 ms /    38 runs   (    1.39 ms per token,   717.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.50 ms /   268 tokens (    0.48 ms per token,  2085.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.27 ms /    37 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1741.63 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.59 ms /    28 runs   (    1.38 ms per token,   725.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.32 ms /   226 tokens (    0.44 ms per token,  2252.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.36 ms /    27 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1278.25 ms /   253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      67.59 ms /    48 runs   (    1.41 ms per token,   710.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.91 ms /   320 tokens (    0.42 ms per token,  2354.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1960.76 ms /    47 runs   (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    2188.89 ms /   367 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.32 ms /    36 runs   (    1.43 ms per token,   701.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.36 ms /   279 tokens (    0.45 ms per token,  2208.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.41 ms /    35 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1653.03 ms /   314 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.99 ms /    30 runs   (    1.40 ms per token,   714.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.33 ms /   236 tokens (    0.42 ms per token,  2376.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.57 ms /    29 runs   (   41.64 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1363.07 ms /   265 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.48 ms /    38 runs   (    1.38 ms per token,   724.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.56 ms /   271 tokens (    0.46 ms per token,  2175.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.32 ms /    37 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1736.42 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.01 ms /    29 runs   (    1.41 ms per token,   707.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.23 ms /   274 tokens (    0.46 ms per token,  2187.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.45 ms /    28 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1346.19 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.83 ms /    35 runs   (    1.42 ms per token,   702.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     132.27 ms /   302 tokens (    0.44 ms per token,  2283.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.96 ms /    34 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1615.91 ms /   336 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.59 ms /    35 runs   (    1.42 ms per token,   705.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.45 ms /   256 tokens (    0.40 ms per token,  2474.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.60 ms /    34 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1587.59 ms /   290 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.82 ms /    34 runs   (    1.35 ms per token,   742.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.69 ms /   299 tokens (    0.44 ms per token,  2270.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.07 ms /    33 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1570.17 ms /   332 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.94 ms /    34 runs   (    1.38 ms per token,   724.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.49 ms /   270 tokens (    0.46 ms per token,  2168.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.60 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1563.21 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      29.91 ms /    21 runs   (    1.42 ms per token,   702.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.85 ms /   269 tokens (    0.47 ms per token,  2137.48 tokens per second)\n",
      "llama_print_timings:        eval time =     833.14 ms /    20 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =     999.35 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.86 ms /    28 runs   (    1.39 ms per token,   720.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.77 ms /   248 tokens (    0.41 ms per token,  2436.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.56 ms /    27 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1279.67 ms /   275 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.79 ms /    29 runs   (    1.41 ms per token,   710.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.64 ms /   243 tokens (    0.43 ms per token,  2344.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.39 ms /    28 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1325.98 ms /   271 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.46 ms /    36 runs   (    1.40 ms per token,   713.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.98 ms /   270 tokens (    0.47 ms per token,  2143.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.30 ms /    35 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1652.93 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.78 ms /    28 runs   (    1.42 ms per token,   703.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.71 ms /   279 tokens (    0.46 ms per token,  2184.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.94 ms /    27 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1306.73 ms /   306 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.22 ms /    35 runs   (    1.38 ms per token,   725.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.43 ms /   258 tokens (    0.47 ms per token,  2107.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.32 ms /    34 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1604.32 ms /   292 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.37 ms /    28 runs   (    1.37 ms per token,   729.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.77 ms /   266 tokens (    0.47 ms per token,  2149.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.50 ms /    27 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1300.15 ms /   293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.12 ms /    33 runs   (    1.40 ms per token,   715.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.74 ms /   260 tokens (    0.47 ms per token,  2118.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.16 ms /    32 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1519.11 ms /   292 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.12 ms /    33 runs   (    1.40 ms per token,   715.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.14 ms /   255 tokens (    0.40 ms per token,  2472.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.98 ms /    32 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1498.43 ms /   287 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.45 ms /    34 runs   (    1.40 ms per token,   716.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.79 ms /   264 tokens (    0.47 ms per token,  2115.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.75 ms /    33 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1563.32 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      67.38 ms /    50 runs   (    1.35 ms per token,   742.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     134.69 ms /   317 tokens (    0.42 ms per token,  2353.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2043.06 ms /    49 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2270.07 ms /   366 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.01 ms /    29 runs   (    1.45 ms per token,   690.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.35 ms /   272 tokens (    0.46 ms per token,  2169.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.68 ms /    28 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1348.07 ms /   300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.12 ms /    30 runs   (    1.44 ms per token,   695.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.68 ms /   243 tokens (    0.41 ms per token,  2413.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.06 ms /    29 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1367.13 ms /   272 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.68 ms /    43 runs   (    1.43 ms per token,   697.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     139.77 ms /   341 tokens (    0.41 ms per token,  2439.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1751.69 ms /    42 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1974.95 ms /   383 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.83 ms /    30 runs   (    1.36 ms per token,   734.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.71 ms /   238 tokens (    0.43 ms per token,  2317.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.02 ms /    29 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1366.67 ms /   267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.70 ms /    30 runs   (    1.49 ms per token,   671.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.06 ms /   235 tokens (    0.43 ms per token,  2302.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.81 ms /    29 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1371.59 ms /   264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      30.06 ms /    21 runs   (    1.43 ms per token,   698.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.83 ms /   268 tokens (    0.47 ms per token,  2146.85 tokens per second)\n",
      "llama_print_timings:        eval time =     833.50 ms /    20 runs   (   41.68 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =     998.86 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.40 ms /    29 runs   (    1.43 ms per token,   700.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.96 ms /   245 tokens (    0.42 ms per token,  2356.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.60 ms /    28 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1327.11 ms /   273 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.19 ms /    36 runs   (    1.45 ms per token,   689.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.55 ms /   323 tokens (    0.42 ms per token,  2365.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.31 ms /    35 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1666.78 ms /   358 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.34 ms /    25 runs   (    1.41 ms per token,   707.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     105.97 ms /   254 tokens (    0.42 ms per token,  2396.88 tokens per second)\n",
      "llama_print_timings:        eval time =     999.78 ms /    24 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1154.07 ms /   278 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.47 ms /    36 runs   (    1.46 ms per token,   686.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.32 ms /   264 tokens (    0.48 ms per token,  2089.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.34 ms /    35 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1655.57 ms /   299 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.27 ms /    25 runs   (    1.41 ms per token,   708.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.34 ms /   289 tokens (    0.45 ms per token,  2200.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1000.25 ms /    24 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1179.67 ms /   313 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.77 ms /    36 runs   (    1.41 ms per token,   709.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.77 ms /   265 tokens (    0.48 ms per token,  2074.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.08 ms /    35 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1655.62 ms /   300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.51 ms /    35 runs   (    1.41 ms per token,   706.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.54 ms /   268 tokens (    0.46 ms per token,  2151.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.51 ms /    34 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1608.32 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.24 ms /    33 runs   (    1.43 ms per token,   698.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.04 ms /   262 tokens (    0.47 ms per token,  2129.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.38 ms /    32 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1520.32 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.00 ms /    41 runs   (    1.39 ms per token,   719.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.97 ms /   263 tokens (    0.49 ms per token,  2055.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.53 ms /    40 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1872.47 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.49 ms /    41 runs   (    1.43 ms per token,   701.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.97 ms /   286 tokens (    0.46 ms per token,  2167.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.03 ms /    40 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1878.80 ms /   326 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.08 ms /    37 runs   (    1.43 ms per token,   697.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.54 ms /   276 tokens (    0.46 ms per token,  2163.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.03 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1699.15 ms /   312 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.16 ms /    31 runs   (    1.36 ms per token,   735.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.52 ms /   242 tokens (    0.43 ms per token,  2337.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.45 ms /    30 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1409.93 ms /   272 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.43 ms /    43 runs   (    1.36 ms per token,   735.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.51 ms /   316 tokens (    0.44 ms per token,  2281.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.69 ms /    42 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1970.62 ms /   358 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.11 ms /    35 runs   (    1.40 ms per token,   712.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.70 ms /   262 tokens (    0.47 ms per token,  2118.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.25 ms /    34 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1606.37 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.39 ms /    45 runs   (    1.36 ms per token,   733.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.03 ms /   332 tokens (    0.43 ms per token,  2337.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1834.82 ms /    44 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2062.16 ms /   376 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.84 ms /    38 runs   (    1.39 ms per token,   719.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.63 ms /   265 tokens (    0.47 ms per token,  2143.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.45 ms /    37 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1737.08 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.60 ms /    27 runs   (    1.39 ms per token,   718.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.03 ms /   226 tokens (    0.44 ms per token,  2259.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.47 ms /    26 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1234.51 ms /   252 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.99 ms /    36 runs   (    1.36 ms per token,   734.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.88 ms /   234 tokens (    0.42 ms per token,  2366.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.44 ms /    35 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1623.91 ms /   269 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      68.44 ms /    49 runs   (    1.40 ms per token,   715.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.09 ms /   307 tokens (    0.43 ms per token,  2306.68 tokens per second)\n",
      "llama_print_timings:        eval time =    2000.62 ms /    48 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2227.68 ms /   355 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.93 ms /    39 runs   (    1.36 ms per token,   736.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.90 ms /   305 tokens (    0.44 ms per token,  2277.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.86 ms /    38 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1790.20 ms /   343 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.62 ms /    31 runs   (    1.41 ms per token,   710.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.44 ms /   259 tokens (    0.47 ms per token,  2115.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.97 ms /    30 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1431.25 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.69 ms /    42 runs   (    1.33 ms per token,   754.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.62 ms /   327 tokens (    0.44 ms per token,  2292.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1709.82 ms /    41 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1929.64 ms /   368 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.17 ms /    26 runs   (    1.43 ms per token,   699.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.40 ms /   264 tokens (    0.48 ms per token,  2088.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.49 ms /    25 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1218.61 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.96 ms /    26 runs   (    1.38 ms per token,   723.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.82 ms /   270 tokens (    0.47 ms per token,  2112.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.53 ms /    25 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1219.09 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.09 ms /    37 runs   (    1.35 ms per token,   738.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.12 ms /   281 tokens (    0.45 ms per token,  2210.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.10 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1695.99 ms /   317 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      63.03 ms /    44 runs   (    1.43 ms per token,   698.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.96 ms /   270 tokens (    0.47 ms per token,  2143.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1791.76 ms /    43 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    2003.16 ms /   313 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.63 ms /    38 runs   (    1.39 ms per token,   721.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.93 ms /   298 tokens (    0.45 ms per token,  2225.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.41 ms /    37 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1748.98 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.72 ms /    33 runs   (    1.39 ms per token,   721.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.84 ms /   262 tokens (    0.48 ms per token,  2082.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.12 ms /    32 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1521.61 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.35 ms /    36 runs   (    1.40 ms per token,   715.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     105.00 ms /   249 tokens (    0.42 ms per token,  2371.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.02 ms /    35 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1632.24 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.54 ms /    31 runs   (    1.40 ms per token,   712.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.42 ms /   218 tokens (    0.45 ms per token,  2214.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.56 ms /    30 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1407.37 ms /   248 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.72 ms /    39 runs   (    1.43 ms per token,   699.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.32 ms /   256 tokens (    0.42 ms per token,  2407.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.21 ms /    38 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1765.04 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.17 ms /    28 runs   (    1.36 ms per token,   733.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.37 ms /   246 tokens (    0.41 ms per token,  2426.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.57 ms /    27 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1278.16 ms /   273 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.87 ms /    37 runs   (    1.37 ms per token,   727.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.20 ms /   330 tokens (    0.42 ms per token,  2387.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1501.26 ms /    36 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1709.06 ms /   366 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.30 ms /    35 runs   (    1.38 ms per token,   724.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.03 ms /   266 tokens (    0.48 ms per token,  2077.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.79 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1611.43 ms /   300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.18 ms /    30 runs   (    1.41 ms per token,   711.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.72 ms /   238 tokens (    0.42 ms per token,  2386.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.94 ms /    29 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1364.89 ms /   267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.61 ms /    35 runs   (    1.42 ms per token,   705.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     132.49 ms /   291 tokens (    0.46 ms per token,  2196.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1417.73 ms /    34 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1618.80 ms /   325 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      33.94 ms /    25 runs   (    1.36 ms per token,   736.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.49 ms /   220 tokens (    0.45 ms per token,  2233.77 tokens per second)\n",
      "llama_print_timings:        eval time =     999.19 ms /    24 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1143.60 ms /   244 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.83 ms /    33 runs   (    1.39 ms per token,   720.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.14 ms /   254 tokens (    0.42 ms per token,  2393.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.20 ms /    32 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1502.85 ms /   286 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.09 ms /    39 runs   (    1.36 ms per token,   734.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.24 ms /   270 tokens (    0.48 ms per token,  2089.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.00 ms /    38 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1825.55 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      34.50 ms /    25 runs   (    1.38 ms per token,   724.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.97 ms /   229 tokens (    0.43 ms per token,  2337.45 tokens per second)\n",
      "llama_print_timings:        eval time =     999.49 ms /    24 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1144.02 ms /   253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.36 ms /    29 runs   (    1.36 ms per token,   736.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.42 ms /   237 tokens (    0.42 ms per token,  2383.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.14 ms /    28 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1319.03 ms /   265 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      35.45 ms /    26 runs   (    1.36 ms per token,   733.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.18 ms /   250 tokens (    0.41 ms per token,  2446.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.19 ms /    25 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1191.17 ms /   275 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      32.68 ms /    23 runs   (    1.42 ms per token,   703.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.32 ms /   231 tokens (    0.43 ms per token,  2349.45 tokens per second)\n",
      "llama_print_timings:        eval time =     915.94 ms /    22 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1057.67 ms /   253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.78 ms /    28 runs   (    1.39 ms per token,   721.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.21 ms /   207 tokens (    0.45 ms per token,  2220.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.94 ms /    27 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1269.69 ms /   234 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.46 ms /    29 runs   (    1.40 ms per token,   716.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.51 ms /   242 tokens (    0.42 ms per token,  2407.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.17 ms /    28 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1321.02 ms /   270 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.88 ms /    35 runs   (    1.60 ms per token,   626.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     105.80 ms /   253 tokens (    0.42 ms per token,  2391.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1419.44 ms /    34 runs   (   41.75 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time =    1601.06 ms /   287 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      30.51 ms /    22 runs   (    1.39 ms per token,   721.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.91 ms /   277 tokens (    0.46 ms per token,  2165.62 tokens per second)\n",
      "llama_print_timings:        eval time =     875.00 ms /    21 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1043.56 ms /   298 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.86 ms /    24 runs   (    1.54 ms per token,   651.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.21 ms /   240 tokens (    0.42 ms per token,  2395.02 tokens per second)\n",
      "llama_print_timings:        eval time =     958.72 ms /    23 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1108.20 ms /   263 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.74 ms /    35 runs   (    1.36 ms per token,   733.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.73 ms /   275 tokens (    0.46 ms per token,  2187.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.38 ms /    34 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1607.36 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.16 ms /    33 runs   (    1.37 ms per token,   730.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.87 ms /   239 tokens (    0.42 ms per token,  2393.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.74 ms /    32 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1494.17 ms /   271 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.65 ms /    31 runs   (    1.41 ms per token,   710.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.89 ms /   273 tokens (    0.46 ms per token,  2151.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.80 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1436.22 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.06 ms /    30 runs   (    1.40 ms per token,   713.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.21 ms /   221 tokens (    0.44 ms per token,  2296.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.49 ms /    29 runs   (   41.64 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1361.38 ms /   250 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.54 ms /    31 runs   (    1.37 ms per token,   728.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.40 ms /   236 tokens (    0.42 ms per token,  2374.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.28 ms /    30 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1407.20 ms /   266 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      64.66 ms /    46 runs   (    1.41 ms per token,   711.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.36 ms /   322 tokens (    0.42 ms per token,  2361.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1876.26 ms /    45 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2100.51 ms /   367 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.71 ms /    34 runs   (    1.37 ms per token,   727.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.47 ms /   237 tokens (    0.42 ms per token,  2382.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.35 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1537.80 ms /   270 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.84 ms /    38 runs   (    1.36 ms per token,   733.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.39 ms /   311 tokens (    0.44 ms per token,  2297.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.65 ms /    37 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1748.85 ms /   348 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.64 ms /    38 runs   (    1.41 ms per token,   708.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.27 ms /   255 tokens (    0.40 ms per token,  2469.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.52 ms /    37 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1718.62 ms /   292 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      36.56 ms /    27 runs   (    1.35 ms per token,   738.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.10 ms /   255 tokens (    0.40 ms per token,  2473.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.98 ms /    26 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1235.87 ms /   281 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.06 ms /    28 runs   (    1.39 ms per token,   716.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.36 ms /   231 tokens (    0.43 ms per token,  2348.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.69 ms /    27 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1276.26 ms /   258 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.88 ms /    35 runs   (    1.37 ms per token,   730.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.17 ms /   271 tokens (    0.46 ms per token,  2165.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.73 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1607.72 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.84 ms /    33 runs   (    1.39 ms per token,   719.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.10 ms /   290 tokens (    0.45 ms per token,  2229.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.82 ms /    32 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1526.25 ms /   322 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.03 ms /    30 runs   (    1.37 ms per token,   731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.29 ms /   419 tokens (    0.43 ms per token,  2311.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1210.29 ms /    29 runs   (   41.73 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time =    1450.61 ms /   448 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.43 ms /    31 runs   (    1.34 ms per token,   748.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.92 ms /   249 tokens (    0.41 ms per token,  2443.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.76 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1409.10 ms /   279 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.82 ms /    28 runs   (    1.39 ms per token,   721.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.42 ms /   274 tokens (    0.46 ms per token,  2184.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.27 ms /    27 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1305.11 ms /   301 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.83 ms /    31 runs   (    1.41 ms per token,   707.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.59 ms /   268 tokens (    0.47 ms per token,  2133.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.90 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1434.37 ms /   298 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.91 ms /    30 runs   (    1.36 ms per token,   733.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.06 ms /   259 tokens (    0.48 ms per token,  2087.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.22 ms /    29 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1388.07 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.30 ms /    29 runs   (    1.42 ms per token,   702.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.99 ms /   254 tokens (    0.41 ms per token,  2466.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.34 ms /    28 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1325.35 ms /   282 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.41 ms /    34 runs   (    1.36 ms per token,   732.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.15 ms /   276 tokens (    0.46 ms per token,  2170.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.02 ms /    33 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1565.86 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.63 ms /    40 runs   (    1.39 ms per token,   719.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     137.45 ms /   322 tokens (    0.43 ms per token,  2342.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1626.17 ms /    39 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1839.68 ms /   361 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.44 ms /    42 runs   (    1.39 ms per token,   718.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.98 ms /   260 tokens (    0.47 ms per token,  2114.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.35 ms /    41 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1911.21 ms /   301 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      63.92 ms /    47 runs   (    1.36 ms per token,   735.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     134.59 ms /   315 tokens (    0.43 ms per token,  2340.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1917.63 ms /    46 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2140.48 ms /   361 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.32 ms /    31 runs   (    1.40 ms per token,   715.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.52 ms /   242 tokens (    0.42 ms per token,  2407.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.38 ms /    30 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1408.70 ms /   272 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.94 ms /    41 runs   (    1.36 ms per token,   732.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.20 ms /   288 tokens (    0.45 ms per token,  2246.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.80 ms /    40 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1871.59 ms /   328 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      27.26 ms /    20 runs   (    1.36 ms per token,   733.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.34 ms /   202 tokens (    0.46 ms per token,  2187.54 tokens per second)\n",
      "llama_print_timings:        eval time =     790.86 ms /    19 runs   (   41.62 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =     920.12 ms /   221 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.53 ms /    29 runs   (    1.36 ms per token,   733.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.59 ms /   256 tokens (    0.40 ms per token,  2471.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.71 ms /    28 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1324.19 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.72 ms /    33 runs   (    1.42 ms per token,   706.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.65 ms /   233 tokens (    0.42 ms per token,  2361.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.74 ms /    32 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1494.28 ms /   265 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.27 ms /    32 runs   (    1.41 ms per token,   706.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.02 ms /   266 tokens (    0.47 ms per token,  2144.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.66 ms /    31 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1477.08 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.70 ms /    31 runs   (    1.38 ms per token,   725.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.00 ms /   249 tokens (    0.41 ms per token,  2441.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.55 ms /    30 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1409.56 ms /   279 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.82 ms /    42 runs   (    1.38 ms per token,   726.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     139.99 ms /   343 tokens (    0.41 ms per token,  2450.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1709.53 ms /    41 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1929.15 ms /   384 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.96 ms /    29 runs   (    1.38 ms per token,   725.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.57 ms /   270 tokens (    0.47 ms per token,  2150.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.65 ms /    28 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1346.44 ms /   298 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.86 ms /    39 runs   (    1.38 ms per token,   724.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.20 ms /   255 tokens (    0.40 ms per token,  2470.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1582.83 ms /    38 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1759.28 ms /   293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.64 ms /    29 runs   (    1.37 ms per token,   731.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.33 ms /   246 tokens (    0.41 ms per token,  2427.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.37 ms /    28 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1322.18 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.11 ms /    38 runs   (    1.35 ms per token,   743.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.13 ms /   272 tokens (    0.46 ms per token,  2173.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.77 ms /    37 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1737.19 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.71 ms /    38 runs   (    1.41 ms per token,   707.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.02 ms /   262 tokens (    0.47 ms per token,  2129.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.73 ms /    37 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1737.96 ms /   299 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.79 ms /    37 runs   (    1.37 ms per token,   728.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.33 ms /   269 tokens (    0.46 ms per token,  2163.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.02 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1693.88 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.49 ms /    33 runs   (    1.41 ms per token,   709.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.08 ms /   273 tokens (    0.46 ms per token,  2182.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.22 ms /    32 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1521.69 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.09 ms /    33 runs   (    1.43 ms per token,   700.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.08 ms /   279 tokens (    0.46 ms per token,  2195.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.49 ms /    32 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1523.78 ms /   311 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.53 ms /    38 runs   (    1.38 ms per token,   723.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.00 ms /   267 tokens (    0.47 ms per token,  2135.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.61 ms /    37 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1738.09 ms /   304 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.06 ms /    41 runs   (    1.37 ms per token,   731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.64 ms /   304 tokens (    0.43 ms per token,  2309.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.43 ms /    40 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1876.24 ms /   344 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.66 ms /    37 runs   (    1.42 ms per token,   702.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.46 ms /   251 tokens (    0.41 ms per token,  2449.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.63 ms /    36 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1673.44 ms /   287 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.97 ms /    29 runs   (    1.41 ms per token,   707.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.55 ms /   227 tokens (    0.43 ms per token,  2327.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.42 ms /    28 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1319.69 ms /   255 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.12 ms /    29 runs   (    1.38 ms per token,   722.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.20 ms /   245 tokens (    0.41 ms per token,  2420.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.30 ms /    28 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1321.87 ms /   273 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      60.20 ms /    44 runs   (    1.37 ms per token,   730.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.31 ms /   325 tokens (    0.43 ms per token,  2349.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1793.52 ms /    43 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2014.37 ms /   368 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.37 ms /    35 runs   (    1.41 ms per token,   708.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.48 ms /   275 tokens (    0.46 ms per token,  2191.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.80 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1609.43 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.16 ms /    37 runs   (    1.38 ms per token,   723.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.63 ms /   321 tokens (    0.42 ms per token,  2366.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1501.11 ms /    36 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1706.52 ms /   357 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.76 ms /    32 runs   (    1.40 ms per token,   714.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.47 ms /   260 tokens (    0.49 ms per token,  2055.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.69 ms /    31 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1479.41 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.56 ms /    33 runs   (    1.41 ms per token,   708.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.53 ms /   280 tokens (    0.45 ms per token,  2212.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.57 ms /    32 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1522.70 ms /   312 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      59.55 ms /    43 runs   (    1.38 ms per token,   722.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.91 ms /   300 tokens (    0.45 ms per token,  2207.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.96 ms /    42 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1969.24 ms /   342 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      64.03 ms /    48 runs   (    1.33 ms per token,   749.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     143.84 ms /   333 tokens (    0.43 ms per token,  2315.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1960.23 ms /    47 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2193.58 ms /   380 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.89 ms /    31 runs   (    1.38 ms per token,   722.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     105.11 ms /   251 tokens (    0.42 ms per token,  2387.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.75 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1414.42 ms /   281 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.43 ms /    29 runs   (    1.39 ms per token,   717.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.56 ms /   228 tokens (    0.44 ms per token,  2267.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.32 ms /    28 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1322.42 ms /   256 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.04 ms /    31 runs   (    1.39 ms per token,   720.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.30 ms /   278 tokens (    0.46 ms per token,  2183.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.00 ms /    30 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1436.01 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.86 ms /    28 runs   (    1.39 ms per token,   720.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.34 ms /   225 tokens (    0.44 ms per token,  2265.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.37 ms /    27 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1277.39 ms /   252 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.47 ms /    38 runs   (    1.38 ms per token,   724.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.69 ms /   279 tokens (    0.46 ms per token,  2151.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.79 ms /    37 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1743.45 ms /   316 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.45 ms /    37 runs   (    1.39 ms per token,   719.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.82 ms /   257 tokens (    0.49 ms per token,  2042.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.76 ms /    36 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1697.03 ms /   293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.48 ms /    39 runs   (    1.40 ms per token,   715.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.47 ms /   290 tokens (    0.45 ms per token,  2239.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.23 ms /    38 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1788.83 ms /   328 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.98 ms /    40 runs   (    1.40 ms per token,   714.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.27 ms /   331 tokens (    0.43 ms per token,  2326.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1626.45 ms /    39 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1845.72 ms /   370 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.90 ms /    31 runs   (    1.45 ms per token,   690.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.58 ms /   281 tokens (    0.45 ms per token,  2219.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.30 ms /    30 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1437.02 ms /   311 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.92 ms /    37 runs   (    1.40 ms per token,   712.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.67 ms /   275 tokens (    0.46 ms per token,  2188.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.18 ms /    36 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1696.38 ms /   311 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.56 ms /    36 runs   (    1.43 ms per token,   698.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.02 ms /   269 tokens (    0.48 ms per token,  2085.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.46 ms /    35 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1657.03 ms /   304 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.79 ms /    31 runs   (    1.48 ms per token,   677.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.99 ms /   265 tokens (    0.48 ms per token,  2086.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.27 ms /    30 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1438.90 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      34.88 ms /    25 runs   (    1.40 ms per token,   716.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.69 ms /   242 tokens (    0.42 ms per token,  2403.51 tokens per second)\n",
      "llama_print_timings:        eval time =     999.38 ms /    24 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1147.04 ms /   266 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.70 ms /    30 runs   (    1.42 ms per token,   702.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.79 ms /   271 tokens (    0.48 ms per token,  2104.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.42 ms /    29 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1395.72 ms /   300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.39 ms /    31 runs   (    1.40 ms per token,   714.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.64 ms /   256 tokens (    0.42 ms per token,  2400.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.02 ms /    30 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1415.97 ms /   286 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.13 ms /    33 runs   (    1.40 ms per token,   715.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.64 ms /   242 tokens (    0.42 ms per token,  2404.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.06 ms /    32 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1496.63 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      54.47 ms /    39 runs   (    1.40 ms per token,   716.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.37 ms /   264 tokens (    0.47 ms per token,  2139.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.33 ms /    38 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1780.84 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.86 ms /    29 runs   (    1.37 ms per token,   727.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.38 ms /   237 tokens (    0.43 ms per token,  2314.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.30 ms /    28 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1323.62 ms /   265 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.97 ms /    32 runs   (    1.41 ms per token,   711.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.09 ms /   266 tokens (    0.48 ms per token,  2093.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.75 ms /    31 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1479.41 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.50 ms /    42 runs   (    1.37 ms per token,   730.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     132.30 ms /   297 tokens (    0.45 ms per token,  2244.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.89 ms /    41 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1919.35 ms /   338 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.94 ms /    35 runs   (    1.40 ms per token,   715.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.35 ms /   271 tokens (    0.46 ms per token,  2162.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.55 ms /    34 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1607.80 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.61 ms /    30 runs   (    1.39 ms per token,   721.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.09 ms /   250 tokens (    0.41 ms per token,  2448.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.06 ms /    29 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1366.54 ms /   279 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.52 ms /    42 runs   (    1.39 ms per token,   717.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.64 ms /   266 tokens (    0.46 ms per token,  2151.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.30 ms /    41 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1911.10 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.25 ms /    35 runs   (    1.38 ms per token,   725.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.25 ms /   250 tokens (    0.41 ms per token,  2444.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.30 ms /    34 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1584.12 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.11 ms /    31 runs   (    1.39 ms per token,   719.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.54 ms /   259 tokens (    0.47 ms per token,  2113.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.87 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1429.88 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.12 ms /    30 runs   (    1.44 ms per token,   695.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.79 ms /   220 tokens (    0.44 ms per token,  2296.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.47 ms /    29 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1362.09 ms /   249 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.15 ms /    30 runs   (    1.40 ms per token,   711.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.83 ms /   234 tokens (    0.42 ms per token,  2367.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.92 ms /    29 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1364.09 ms /   263 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.55 ms /    32 runs   (    1.39 ms per token,   718.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.68 ms /   253 tokens (    0.41 ms per token,  2463.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.41 ms /    31 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1454.56 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.79 ms /    29 runs   (    1.44 ms per token,   693.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.41 ms /   275 tokens (    0.47 ms per token,  2108.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.66 ms /    28 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1353.37 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.18 ms /    39 runs   (    1.44 ms per token,   694.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.12 ms /   327 tokens (    0.43 ms per token,  2300.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.79 ms /    38 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1802.91 ms /   365 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.34 ms /    34 runs   (    1.36 ms per token,   733.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.89 ms /   276 tokens (    0.46 ms per token,  2192.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.85 ms /    33 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1563.60 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.10 ms /    29 runs   (    1.45 ms per token,   688.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.74 ms /   281 tokens (    0.47 ms per token,  2133.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.01 ms /    28 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1356.41 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.19 ms /    36 runs   (    1.39 ms per token,   717.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.18 ms /   266 tokens (    0.48 ms per token,  2075.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.13 ms /    35 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1654.59 ms /   301 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.04 ms /    33 runs   (    1.40 ms per token,   716.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.24 ms /   268 tokens (    0.47 ms per token,  2106.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.55 ms /    32 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1524.52 ms /   300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.09 ms /    31 runs   (    1.39 ms per token,   719.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.86 ms /   244 tokens (    0.41 ms per token,  2419.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.66 ms /    30 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1409.61 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      60.72 ms /    44 runs   (    1.38 ms per token,   724.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.26 ms /   302 tokens (    0.45 ms per token,  2232.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1792.35 ms /    43 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2011.43 ms /   345 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.32 ms /    42 runs   (    1.36 ms per token,   732.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     134.17 ms /   300 tokens (    0.45 ms per token,  2235.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1709.27 ms /    41 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1922.93 ms /   341 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.93 ms /    28 runs   (    1.35 ms per token,   738.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.19 ms /   312 tokens (    0.43 ms per token,  2307.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.57 ms /    27 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1312.88 ms /   339 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      30.30 ms /    22 runs   (    1.38 ms per token,   725.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.77 ms /   224 tokens (    0.44 ms per token,  2267.80 tokens per second)\n",
      "llama_print_timings:        eval time =     874.43 ms /    21 runs   (   41.64 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =    1014.08 ms /   245 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =     129.77 ms /    98 runs   (    1.32 ms per token,   755.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.65 ms /   339 tokens (    0.42 ms per token,  2393.31 tokens per second)\n",
      "llama_print_timings:        eval time =    4046.25 ms /    97 runs   (   41.71 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    4370.26 ms /   436 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.90 ms /    37 runs   (    1.38 ms per token,   726.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.06 ms /   271 tokens (    0.48 ms per token,  2099.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.73 ms /    36 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1697.56 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.92 ms /    30 runs   (    1.40 ms per token,   715.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.54 ms /   237 tokens (    0.42 ms per token,  2381.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.66 ms /    29 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1363.36 ms /   266 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      79.72 ms /    63 runs   (    1.27 ms per token,   790.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     171.78 ms /   386 tokens (    0.45 ms per token,  2247.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2587.19 ms /    62 runs   (   41.73 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time =    2870.47 ms /   448 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.03 ms /    32 runs   (    1.41 ms per token,   710.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.52 ms /   265 tokens (    0.48 ms per token,  2078.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.63 ms /    31 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1480.26 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      51.93 ms /    37 runs   (    1.40 ms per token,   712.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.44 ms /   272 tokens (    0.46 ms per token,  2151.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.36 ms /    36 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1697.34 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.30 ms /    35 runs   (    1.35 ms per token,   739.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     105.90 ms /   253 tokens (    0.42 ms per token,  2389.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.24 ms /    34 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1586.69 ms /   287 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.58 ms /    42 runs   (    1.32 ms per token,   755.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.92 ms /   261 tokens (    0.49 ms per token,  2056.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.03 ms /    41 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1911.27 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      55.95 ms /    38 runs   (    1.47 ms per token,   679.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.22 ms /   275 tokens (    0.47 ms per token,  2128.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.67 ms /    37 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1748.26 ms /   312 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.75 ms /    32 runs   (    1.40 ms per token,   715.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     132.85 ms /   287 tokens (    0.46 ms per token,  2160.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.79 ms /    31 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1485.65 ms /   318 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.59 ms /    31 runs   (    1.41 ms per token,   711.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.93 ms /   243 tokens (    0.42 ms per token,  2407.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.62 ms /    30 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1409.52 ms /   273 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      49.17 ms /    35 runs   (    1.40 ms per token,   711.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.43 ms /   268 tokens (    0.46 ms per token,  2153.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.75 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1607.60 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.89 ms /    27 runs   (    1.40 ms per token,   712.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.41 ms /   268 tokens (    0.48 ms per token,  2087.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.24 ms /    26 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1264.12 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.54 ms /    31 runs   (    1.50 ms per token,   666.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.75 ms /   239 tokens (    0.43 ms per token,  2325.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1251.07 ms /    30 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1416.79 ms /   269 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      41.96 ms /    31 runs   (    1.35 ms per token,   738.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.66 ms /   310 tokens (    0.43 ms per token,  2319.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.59 ms /    30 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1441.55 ms /   340 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.72 ms /    39 runs   (    1.35 ms per token,   739.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.78 ms /   257 tokens (    0.48 ms per token,  2093.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.27 ms /    38 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1778.00 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.11 ms /    31 runs   (    1.39 ms per token,   719.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.85 ms /   282 tokens (    0.45 ms per token,  2223.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.27 ms /    30 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1436.00 ms /   312 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.18 ms /    30 runs   (    1.41 ms per token,   711.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.80 ms /   304 tokens (    0.45 ms per token,  2222.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.29 ms /    29 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1404.56 ms /   333 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.84 ms /    33 runs   (    1.39 ms per token,   719.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.67 ms /   277 tokens (    0.46 ms per token,  2152.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.76 ms /    32 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1525.88 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.22 ms /    33 runs   (    1.43 ms per token,   698.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.23 ms /   287 tokens (    0.45 ms per token,  2220.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.65 ms /    32 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1527.11 ms /   319 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      42.84 ms /    31 runs   (    1.38 ms per token,   723.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.20 ms /   241 tokens (    0.43 ms per token,  2335.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.80 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1411.86 ms /   271 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.24 ms /    34 runs   (    1.42 ms per token,   704.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.37 ms /   297 tokens (    0.45 ms per token,  2226.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.37 ms /    33 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1574.50 ms /   330 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      58.91 ms /    42 runs   (    1.40 ms per token,   712.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.41 ms /   264 tokens (    0.48 ms per token,  2088.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.40 ms /    41 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1914.29 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      43.54 ms /    31 runs   (    1.40 ms per token,   711.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.16 ms /   231 tokens (    0.44 ms per token,  2283.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.57 ms /    30 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1410.98 ms /   261 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.61 ms /    35 runs   (    1.39 ms per token,   719.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.19 ms /   273 tokens (    0.46 ms per token,  2180.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.86 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1608.68 ms /   307 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.94 ms /    38 runs   (    1.42 ms per token,   704.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.29 ms /   284 tokens (    0.46 ms per token,  2179.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.93 ms /    37 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1745.18 ms /   321 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.98 ms /    40 runs   (    1.42 ms per token,   701.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.83 ms /   291 tokens (    0.46 ms per token,  2174.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1625.51 ms /    39 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1837.52 ms /   330 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.00 ms /    36 runs   (    1.39 ms per token,   720.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.97 ms /   249 tokens (    0.41 ms per token,  2441.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.95 ms /    35 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1628.89 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      59.04 ms /    43 runs   (    1.37 ms per token,   728.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.97 ms /   266 tokens (    0.48 ms per token,  2078.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.04 ms /    42 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1958.21 ms /   308 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.69 ms /    38 runs   (    1.39 ms per token,   721.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.30 ms /   320 tokens (    0.43 ms per token,  2347.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.63 ms /    37 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    1750.60 ms /   357 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      56.65 ms /    37 runs   (    1.53 ms per token,   653.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     130.92 ms /   282 tokens (    0.46 ms per token,  2154.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1501.72 ms /    36 runs   (   41.71 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    1709.27 ms /   318 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      38.10 ms /    27 runs   (    1.41 ms per token,   708.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.88 ms /   265 tokens (    0.48 ms per token,  2072.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.60 ms /    26 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1263.52 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      59.48 ms /    41 runs   (    1.45 ms per token,   689.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.78 ms /   281 tokens (    0.46 ms per token,  2165.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.89 ms /    40 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1877.91 ms /   321 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.97 ms /    38 runs   (    1.42 ms per token,   704.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.78 ms /   280 tokens (    0.46 ms per token,  2157.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1542.15 ms /    37 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1745.88 ms /   317 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      48.89 ms /    35 runs   (    1.40 ms per token,   715.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.40 ms /   241 tokens (    0.42 ms per token,  2400.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.13 ms /    34 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1583.25 ms /   275 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.87 ms /    36 runs   (    1.41 ms per token,   707.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.54 ms /   259 tokens (    0.47 ms per token,  2113.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.15 ms /    35 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1649.14 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      72.95 ms /    51 runs   (    1.43 ms per token,   699.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     131.54 ms /   304 tokens (    0.43 ms per token,  2311.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2084.16 ms /    50 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2315.25 ms /   354 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      68.93 ms /    48 runs   (    1.44 ms per token,   696.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.61 ms /   286 tokens (    0.45 ms per token,  2241.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1958.65 ms /    47 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    2179.39 ms /   333 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      82.15 ms /    59 runs   (    1.39 ms per token,   718.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.22 ms /   280 tokens (    0.46 ms per token,  2183.76 tokens per second)\n",
      "llama_print_timings:        eval time =    2417.11 ms /    58 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    2657.43 ms /   338 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.76 ms /    33 runs   (    1.42 ms per token,   705.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.28 ms /   263 tokens (    0.48 ms per token,  2082.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.01 ms /    32 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1522.11 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      39.74 ms /    27 runs   (    1.47 ms per token,   679.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.60 ms /   262 tokens (    0.49 ms per token,  2053.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.43 ms /    26 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1264.36 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      52.73 ms /    38 runs   (    1.39 ms per token,   720.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.81 ms /   260 tokens (    0.47 ms per token,  2117.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.26 ms /    37 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1735.23 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      37.84 ms /    27 runs   (    1.40 ms per token,   713.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.95 ms /   240 tokens (    0.43 ms per token,  2331.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.95 ms /    26 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1237.01 ms /   266 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      65.88 ms /    48 runs   (    1.37 ms per token,   728.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     147.36 ms /   383 tokens (    0.38 ms per token,  2599.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1961.36 ms /    47 runs   (   41.73 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time =    2199.04 ms /   430 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      89.42 ms /    67 runs   (    1.33 ms per token,   749.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     143.58 ms /   347 tokens (    0.41 ms per token,  2416.75 tokens per second)\n",
      "llama_print_timings:        eval time =    2752.51 ms /    66 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    3019.78 ms /   413 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      75.17 ms /    54 runs   (    1.39 ms per token,   718.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.66 ms /   333 tokens (    0.42 ms per token,  2401.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2210.05 ms /    53 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2450.16 ms /   386 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      50.48 ms /    35 runs   (    1.44 ms per token,   693.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.15 ms /   255 tokens (    0.40 ms per token,  2472.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.57 ms /    34 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1586.77 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      76.16 ms /    58 runs   (    1.31 ms per token,   761.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     172.08 ms /   389 tokens (    0.44 ms per token,  2260.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2378.30 ms /    57 runs   (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    2654.81 ms /   446 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      74.28 ms /    53 runs   (    1.40 ms per token,   713.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     147.03 ms /   372 tokens (    0.40 ms per token,  2530.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2169.06 ms /    52 runs   (   41.71 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    2415.84 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      84.45 ms /    62 runs   (    1.36 ms per token,   734.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     145.53 ms /   365 tokens (    0.40 ms per token,  2508.02 tokens per second)\n",
      "llama_print_timings:        eval time =    2544.70 ms /    61 runs   (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =    2805.84 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      82.85 ms /    61 runs   (    1.36 ms per token,   736.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     139.10 ms /   333 tokens (    0.42 ms per token,  2394.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2501.65 ms /    60 runs   (   41.69 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =    2753.70 ms /   393 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.48 ms /    34 runs   (    1.37 ms per token,   731.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.59 ms /   256 tokens (    0.40 ms per token,  2471.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.56 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1540.65 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.50 ms /    33 runs   (    1.41 ms per token,   709.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     103.44 ms /   256 tokens (    0.40 ms per token,  2474.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.87 ms /    32 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1498.75 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      46.18 ms /    34 runs   (    1.36 ms per token,   736.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.83 ms /   239 tokens (    0.43 ms per token,  2324.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.39 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1541.31 ms /   272 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      53.43 ms /    39 runs   (    1.37 ms per token,   729.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.63 ms /   257 tokens (    0.48 ms per token,  2062.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1582.97 ms /    38 runs   (   41.66 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1781.19 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      40.29 ms /    28 runs   (    1.44 ms per token,   694.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.04 ms /   260 tokens (    0.49 ms per token,  2046.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.93 ms /    27 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1307.31 ms /   287 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.90 ms /    35 runs   (    1.37 ms per token,   730.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.18 ms /   257 tokens (    0.49 ms per token,  2053.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.19 ms /    34 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1607.21 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      57.00 ms /    41 runs   (    1.39 ms per token,   719.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.29 ms /   258 tokens (    0.47 ms per token,  2109.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.71 ms /    40 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1867.04 ms /   298 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      44.44 ms /    32 runs   (    1.39 ms per token,   720.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     125.11 ms /   267 tokens (    0.47 ms per token,  2134.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.51 ms /    31 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1477.05 ms /   298 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.90 ms /    35 runs   (    1.37 ms per token,   730.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.30 ms /   293 tokens (    0.44 ms per token,  2265.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.85 ms /    34 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1611.85 ms /   327 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      47.94 ms /    34 runs   (    1.41 ms per token,   709.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     102.62 ms /   251 tokens (    0.41 ms per token,  2445.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.41 ms /    33 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1541.88 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      45.29 ms /    33 runs   (    1.37 ms per token,   728.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.47 ms /   237 tokens (    0.42 ms per token,  2382.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.80 ms /    32 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1494.19 ms /   269 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     247.09 ms\n",
      "llama_print_timings:      sample time =      61.94 ms /    44 runs   (    1.41 ms per token,   710.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.82 ms /   313 tokens (    0.43 ms per token,  2304.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1792.49 ms /    43 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    2013.28 ms /   356 tokens\n"
     ]
    }
   ],
   "source": [
    "model_outputs = []\n",
    "for pos in range(len(df)):\n",
    "    # Construction of the prompt for Hermes 2 Pro\n",
    "    question = df.iloc[pos][\"question\"]\n",
    "    function = df.iloc[pos]['function']\n",
    "    final_prompt = (\n",
    "        \"<|im_start|>system\\n\"\n",
    "        \"You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. \"\n",
    "        \"You may call one or more functions to assist with the user query. \"\n",
    "        \"Don't make assumptions about what values to plug into functions. \"\n",
    "        \"Here are the available tools: <tools> [\" + json.dumps(function) +\n",
    "        \"] </tools> Use the following pydantic model json schema for each tool call you will make: \"\n",
    "        \"{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']} \"\n",
    "        \"For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows: \"\n",
    "        \"<tool_call>\\n\"\n",
    "        \"{'arguments': <args-dict>, 'name': <function-name>}\"\n",
    "        \"</tool_call><|im_end|>\\n\"\n",
    "        \"<|im_start|>user\\n\" + question +\n",
    "        \"<|im_start|>assistant\\n\"\n",
    "        \"<tool_call>\"\n",
    "    )\n",
    "    try:\n",
    "        response = llm(final_prompt, temperature=0, seed=0, max_tokens=None)\n",
    "        # extract from the response only the first of nested brackets\n",
    "        result = extract_first_of_nested_brackets(response['choices'][0]['text'])\n",
    "        # standardize model_output\n",
    "        final_result = str(json_repair.loads(result)[\"name\"]) + \",\" + str(json_repair.loads(result)[\"arguments\"])\n",
    "        final_result = final_result.replace(\"'\",'\"')\n",
    "        final_result = final_result.replace(\" \", \"\")\n",
    "        model_outputs.append(final_result)\n",
    "    except:\n",
    "        model_outputs.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21eec7ee-9696-4c85-8b6c-f25942a54cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:36:27.345030Z",
     "iopub.status.busy": "2024-07-08T09:36:27.344812Z",
     "iopub.status.idle": "2024-07-08T09:36:27.354146Z",
     "shell.execute_reply": "2024-07-08T09:36:27.353486Z",
     "shell.execute_reply.started": "2024-07-08T09:36:27.345011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possible_answer</th>\n",
       "      <th>model_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calculate_triangle_area,{\"base\":[10],\"height\":...</td>\n",
       "      <td>calculate_triangle_area,{\"base\":10,\"height\":5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math.factorial,{\"number\":[5]}</td>\n",
       "      <td>math.factorial,{\"number\":5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>math.hypot,{\"x\":[4],\"y\":[5],\"z\":[\"\",0]}</td>\n",
       "      <td>math.hypot,{\"x\":4,\"y\":5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algebra.quadratic_roots,{\"a\":[1],\"b\":[-3],\"c\":...</td>\n",
       "      <td>algebra.quadratic_roots,{\"a\":1,\"b\":-3,\"c\":2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>solve_quadratic_equation,{\"a\":[2],\"b\":[6],\"c\":...</td>\n",
       "      <td>solve_quadratic_equation,{\"a\":2,\"b\":6,\"c\":5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     possible_answer  \\\n",
       "0  calculate_triangle_area,{\"base\":[10],\"height\":...   \n",
       "1                      math.factorial,{\"number\":[5]}   \n",
       "2            math.hypot,{\"x\":[4],\"y\":[5],\"z\":[\"\",0]}   \n",
       "3  algebra.quadratic_roots,{\"a\":[1],\"b\":[-3],\"c\":...   \n",
       "4  solve_quadratic_equation,{\"a\":[2],\"b\":[6],\"c\":...   \n",
       "\n",
       "                                     model_output  \n",
       "0  calculate_triangle_area,{\"base\":10,\"height\":5}  \n",
       "1                     math.factorial,{\"number\":5}  \n",
       "2                        math.hypot,{\"x\":4,\"y\":5}  \n",
       "3    algebra.quadratic_roots,{\"a\":1,\"b\":-3,\"c\":2}  \n",
       "4    solve_quadratic_equation,{\"a\":2,\"b\":6,\"c\":5}  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"possible_answer\"] = possible_answers\n",
    "df[\"model_output\"] = model_outputs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6408785-a86a-4eb9-9d39-bd73284571bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T09:36:27.354949Z",
     "iopub.status.busy": "2024-07-08T09:36:27.354794Z",
     "iopub.status.idle": "2024-07-08T09:36:27.384562Z",
     "shell.execute_reply": "2024-07-08T09:36:27.383267Z",
     "shell.execute_reply.started": "2024-07-08T09:36:27.354934Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"results_Hermes2Pro.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
